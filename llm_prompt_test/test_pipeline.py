#!/usr/bin/env python3
"""
íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì†Œê·œëª¨ ë°ì´í„°ë¡œ íŒŒì´í”„ë¼ì¸ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸
"""

import sys
import os
from pathlib import Path

def test_basic_functionality(metadata_path):
    """ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("=== Testing Basic Functionality ===")
    
    # 1. íŒŒì¼ ì¡´ì¬ í™•ì¸
    required_files = [
        'automated_prompt_generator.py',
        'llm_output_normalizer.py', 
        'object_name_generator.py',
        'run_automated_pipeline.py',
        'pipeline_config.json'
    ]
    
    missing_files = []
    for file in required_files:
        if not os.path.exists(file):
            missing_files.append(file)
        else:
            print(f"âœ“ {file} exists")
    
    if missing_files:
        print(f"âœ— Missing files: {missing_files}")
        return False
    
    # 2. ëª¨ë“ˆ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸
    try:
        from automated_prompt_generator import PromptGenerator
        print("âœ“ PromptGenerator import successful")
        
        from llm_output_normalizer import LLMOutputNormalizer
        print("âœ“ LLMOutputNormalizer import successful")
        
        from object_name_generator import ObjectNameGenerator
        print("âœ“ ObjectNameGenerator import successful")
        
    except ImportError as e:
        print(f"âœ— Import error: {e}")
        return False
    
    # 3. ë©”íƒ€ë°ì´í„° íŒŒì¼ í™•ì¸
    if os.path.exists(metadata_path):
        print(f"âœ“ Metadata file exists: {metadata_path}")
    else:
        print(f"âœ— Metadata file not found: {metadata_path}")
        print("Available datasets:")
        datasets_dir = "../datasets"
        if os.path.exists(datasets_dir):
            for item in os.listdir(datasets_dir):
                item_path = os.path.join(datasets_dir, item)
                if os.path.isdir(item_path):
                    metadata_file = os.path.join(item_path, "metadata.csv")
                    if os.path.exists(metadata_file):
                        print(f"  - {item}: {metadata_file}")
        return False
    
    print("âœ“ All basic tests passed!")
    return True

def test_small_sample(metadata_path):
    """ì†Œê·œëª¨ ìƒ˜í”Œë¡œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    print("\n=== Testing Small Sample Pipeline ===")
    
    try:
        from automated_prompt_generator import PromptGenerator
        
        # ë§¤ìš° ì‘ì€ ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸ (5ê°œ)
        generator = PromptGenerator(metadata_path, num_samples=5)
        
        # ë°ì´í„° ë¡œë“œ í…ŒìŠ¤íŠ¸
        data = generator.load_and_sample_data()
        if data:
            print(f"âœ“ Successfully loaded {len(data)} samples")
            
            # ì²« ë²ˆì§¸ ìƒ˜í”Œ ì¶œë ¥
            if data:
                print(f"Sample caption: {data[0]['original_caption']}")
        else:
            print("âœ— Failed to load sample data")
            return False
        
        # prompts.txt ìƒì„± í…ŒìŠ¤íŠ¸
        prompts_file = generator.generate_prompts_file("test_prompts.txt")
        if os.path.exists(prompts_file):
            print(f"âœ“ Generated prompts file: {prompts_file}")
        else:
            print("âœ— Failed to generate prompts file")
            return False
        
        print("âœ“ Small sample test passed!")
        return True
        
    except Exception as e:
        print(f"âœ— Small sample test failed: {e}")
        return False

def test_object_name_extraction():
    """ê°ì²´ëª… ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    print("\n=== Testing Object Name Extraction ===")
    
    try:
        from object_name_generator import ObjectNameGenerator
        
        generator = ObjectNameGenerator()
        
        # í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë“¤
        test_prompts = [
            "Dark wooden side table with flat top and drawer",
            "Modern white armchair with curved backrest", 
            "Bushy lavender plant with purple flowers",
            "Rectangular kitchen island with storage",
            "Vintage copper rotary telephone"
        ]
        
        print("Testing fallback object extraction (without LLM):")
        for prompt in test_prompts:
            object_name = generator._fallback_object_extraction(prompt)
            print(f"  '{prompt[:30]}...' â†’ {object_name}")
        
        print("âœ“ Object name extraction test passed!")
        return True
        
    except Exception as e:
        print(f"âœ— Object name extraction test failed: {e}")
        return False

def test_enhanced_normalization():
    """í–¥ìƒëœ ì •ê·œí™” ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\n=== Testing Enhanced Normalization ===")
    
    try:
        from enhanced_normalizer import EnhancedNormalizer
        
        normalizer = EnhancedNormalizer()
        
        # í…ŒìŠ¤íŠ¸ LLM ì¶œë ¥ ìƒì„±
        test_output = '''
Here are the rewritten prompts:

1. "Vintage copper rotary telephone with intricate detailing."
:"An antique, intricately detailed copper rotary phone with ornate engravings, rounded body, and a circular dial pad, sitting on a worn wooden surface."

2. "Two-story brick house with red roof and fence."
:"A traditional two-story brick house with a bright red terra cotta tiled roof, white trim, green grass, and a white picket fence surrounding the property."
        '''
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        test_file = "test_enhanced_output.txt"
        with open(test_file, 'w') as f:
            f.write(test_output)
        
        # í–¥ìƒëœ ì •ê·œí™” í…ŒìŠ¤íŠ¸ (fallback ë°©ì‹ìœ¼ë¡œ)
        llm_results = {"test_model": test_file}
        normalized_data = normalizer.fallback_normalize(llm_results)
        
        if normalized_data:
            print(f"âœ“ Enhanced normalization successful: {len(normalized_data)} entries")
            
            # ê²°ê³¼ í™•ì¸
            for i, entry in enumerate(normalized_data[:2]):
                print(f"Entry {i+1}:")
                print(f"  Object: {entry['object_name']}")
                print(f"  User prompt: {entry['user_prompt']}")
                print(f"  Text prompt: {entry['text_prompt'][:50]}...")
            
            # ì •ë¦¬
            os.remove(test_file)
        else:
            print("âœ— Enhanced normalization failed")
            return False
        
        print("âœ“ Enhanced normalization test passed!")
        return True
        
    except Exception as e:
        print(f"âœ— Enhanced normalization test failed: {e}")
        return False

def get_metadata_path():
    """ì‚¬ìš©ìë¡œë¶€í„° ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì…ë ¥ë°›ê¸°"""
    print("Available datasets:")
    datasets_dir = "../datasets"
    available_datasets = []
    
    if os.path.exists(datasets_dir):
        for item in os.listdir(datasets_dir):
            item_path = os.path.join(datasets_dir, item)
            if os.path.isdir(item_path):
                metadata_file = os.path.join(item_path, "metadata.csv")
                if os.path.exists(metadata_file):
                    available_datasets.append((item, metadata_file))
                    print(f"  {len(available_datasets)}. {item}: {metadata_file}")
    
    if not available_datasets:
        print("No datasets found with metadata.csv files!")
        return None
    
    print(f"  {len(available_datasets) + 1}. Custom path")
    
    while True:
        try:
            choice = input(f"\nSelect dataset (1-{len(available_datasets) + 1}): ").strip()
            
            if choice.isdigit():
                choice_num = int(choice)
                if 1 <= choice_num <= len(available_datasets):
                    return available_datasets[choice_num - 1][1]
                elif choice_num == len(available_datasets) + 1:
                    custom_path = input("Enter custom metadata.csv path: ").strip()
                    if os.path.exists(custom_path):
                        return custom_path
                    else:
                        print(f"File not found: {custom_path}")
                        continue
            
            print("Invalid choice. Please try again.")
            
        except KeyboardInterrupt:
            print("\nOperation cancelled.")
            return None
        except Exception as e:
            print(f"Error: {e}")

def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("Running Pipeline Tests...\n")
    
    # ëª…ë ¹í–‰ ì¸ìë¡œ ë©”íƒ€ë°ì´í„° ê²½ë¡œê°€ ì£¼ì–´ì¡ŒëŠ”ì§€ í™•ì¸
    if len(sys.argv) > 1:
        metadata_path = sys.argv[1]
        if not os.path.exists(metadata_path):
            print(f"Error: Metadata file not found: {metadata_path}")
            sys.exit(1)
    else:
        # ì‚¬ìš©ì ì¸í„°ë™í‹°ë¸Œ ì„ íƒ
        metadata_path = get_metadata_path()
        if not metadata_path:
            print("No metadata file selected. Exiting.")
            sys.exit(1)
    
    print(f"Using metadata file: {metadata_path}\n")
    
    tests = [
        ("Basic Functionality", lambda: test_basic_functionality(metadata_path)),
        ("Small Sample", lambda: test_small_sample(metadata_path)),
        ("Object Name Extraction", test_object_name_extraction),
        ("Enhanced Normalization", test_enhanced_normalization)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\n{'='*50}")
        print(f"Running: {test_name}")
        print('='*50)
        
        if test_func():
            passed += 1
            print(f"âœ“ {test_name} PASSED")
        else:
            print(f"âœ— {test_name} FAILED")
    
    print(f"\n{'='*50}")
    print(f"Test Results: {passed}/{total} tests passed")
    print('='*50)
    
    if passed == total:
        print("ğŸ‰ All tests passed! Pipeline is ready to use.")
        print("\nNext steps:")
        print("1. Install required Ollama models:")
        print("   ollama pull gemma3:1b")
        print("   ollama pull qwen3:1.7b")
        print("2. Run the full pipeline:")
        print(f"   python run_automated_pipeline.py {metadata_path}")
    else:
        print("âŒ Some tests failed. Please fix the issues before running the pipeline.")
        sys.exit(1)

if __name__ == "__main__":
    main()