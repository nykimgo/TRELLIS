#!/usr/bin/env python3
"""
í†µí•© ìë™í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ê¸°
ì „ì²´ í”„ë¡¬í”„íŠ¸ ì¦ê°• í”„ë¡œì„¸ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ì‹¤í–‰
"""

import os
import sys
import subprocess
from pathlib import Path
import json

def check_dependencies():
    """í•„ìˆ˜ ì˜ì¡´ì„± í™•ì¸"""
    print("Checking dependencies...")
    
    # Ollama ì„¤ì¹˜ í™•ì¸
    try:
        result = subprocess.run(["ollama", "--version"], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ“ Ollama is installed")
        else:
            print("âœ— Ollama not found. Please install Ollama first.")
            return False
    except FileNotFoundError:
        print("âœ— Ollama not found. Please install Ollama first.")
        return False
    
    # Python íŒ¨í‚¤ì§€ í™•ì¸
    required_packages = ['pandas', 'openpyxl']
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
            print(f"âœ“ {package} is available")
        except ImportError:
            missing_packages.append(package)
            print(f"âœ— {package} is missing")
    
    if missing_packages:
        print(f"Please install missing packages: pip install {' '.join(missing_packages)}")
        return False
    
    return True

def extract_model_params(model_name):
    """ëª¨ë¸ëª…ì—ì„œ íŒŒë¼ë¯¸í„° í¬ê¸° ì¶”ì¶œ (ì˜ˆ: qwen3:32b-q8_0 -> 32)"""
    try:
        # ':' ì´í›„ ë¶€ë¶„ ì¶”ì¶œ
        if ':' in model_name:
            param_part = model_name.split(':', 1)[1]
            # 'b' ì•ì˜ ìˆ«ì ì¶”ì¶œ
            import re
            match = re.search(r'(\d+(?:\.\d+)?)b', param_part, re.IGNORECASE)
            if match:
                return float(match.group(1))
    except:
        pass
    return 0

def get_best_model_by_params(models):
    """íŒŒë¼ë¯¸í„° í¬ê¸°ê°€ ê°€ì¥ í° ëª¨ë¸ ì„ íƒ"""
    if not models:
        return None
    
    best_model = max(models, key=extract_model_params)
    best_params = extract_model_params(best_model)
    
    print(f"Selected best model by parameter size: {best_model} ({best_params}B params)")
    return best_model

def check_ollama_models(models):
    """ì„¤ì¹˜ëœ Ollama ëª¨ë¸ í™•ì¸"""
    print("Checking available Ollama models...")
    
    try:
        result = subprocess.run(["ollama", "list"], capture_output=True, text=True)
        if result.returncode == 0:
            available_models = []
            lines = result.stdout.strip().split('\n')[1:]  # Skip header
            
            for line in lines:
                if line.strip():
                    model_name = line.split()[0]
                    available_models.append(model_name)
            
            print(f"Available models: {available_models}")
            
            # ìš”ì²­ëœ ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            valid_models = []
            for model in models:
                if model in available_models:
                    params = extract_model_params(model)
                    print(f"âœ“ {model} is available ({params}B params)")
                    valid_models.append(model)
                else:
                    print(f"âœ— {model} is not installed")
                    print(f"  Install with: ollama pull {model}")
            
            return valid_models
        else:
            print("Error checking Ollama models")
            return []
            
    except Exception as e:
        print(f"Error checking models: {e}")
        return []

def run_pipeline(metadata_path, num_samples, models, normalize_output=True, generate_object_names=True):
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    print("=== Starting Automated Prompt Augmentation Pipeline ===")
    print(f"Metadata: {metadata_path}")
    print(f"Samples: {num_samples}")
    print(f"Models: {models}")
    print(f"Normalize output: {normalize_output}")
    print(f"Generate object names: {generate_object_names}")
    print()
    
    # 1. ì˜ì¡´ì„± í™•ì¸
    if not check_dependencies():
        return False
    
    # 2. Ollama ëª¨ë¸ í™•ì¸
    valid_models = check_ollama_models(models)
    if not valid_models:
        print("No valid models found. Please install required models first.")
        return False
    
    print(f"Using models: {valid_models}")
    print()
    
    # 3. ë©”ì¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤í–‰
    print("Step 1: Running main prompt generation...")
    try:
        from automated_prompt_generator import PromptGenerator
        
        generator = PromptGenerator(metadata_path, num_samples)
        excel_path = generator.run_full_pipeline(valid_models)
        
        if not excel_path:
            print("Main pipeline failed!")
            return False
            
        print(f"âœ“ Main pipeline completed: {excel_path}")
        
    except Exception as e:
        print(f"Error in main pipeline: {e}")
        return False
    
    # 4. í–¥ìƒëœ ì •ê·œí™”ëŠ” ë©”ì¸ íŒŒì´í”„ë¼ì¸ì—ì„œ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë¨
    print("\nâœ“ Enhanced normalization and object name generation completed in main pipeline")
    
    print(f"\n=== Pipeline Completed Successfully ===")
    print(f"Final result: {excel_path}")
    print(f"Output directory: {Path(excel_path).parent}")
    
    return True

def get_metadata_path():
    """ì‚¬ìš©ìë¡œë¶€í„° ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì…ë ¥ë°›ê¸°"""
    print("Available datasets:")
    datasets_dir = "../datasets"
    available_datasets = []
    
    if os.path.exists(datasets_dir):
        for item in os.listdir(datasets_dir):
            item_path = os.path.join(datasets_dir, item)
            if os.path.isdir(item_path):
                metadata_file = os.path.join(item_path, "metadata.csv")
                if os.path.exists(metadata_file):
                    available_datasets.append((item, metadata_file))
                    print(f"  {len(available_datasets)}. {item}: {metadata_file}")
    
    if not available_datasets:
        print("No datasets found with metadata.csv files!")
        return None
    
    print(f"  {len(available_datasets) + 1}. Custom path")
    
    while True:
        try:
            choice = input(f"\nSelect dataset (1-{len(available_datasets) + 1}): ").strip()
            
            if choice.isdigit():
                choice_num = int(choice)
                if 1 <= choice_num <= len(available_datasets):
                    return available_datasets[choice_num - 1][1]
                elif choice_num == len(available_datasets) + 1:
                    custom_path = input("Enter custom metadata.csv path: ").strip()
                    if os.path.exists(custom_path):
                        return custom_path
                    else:
                        print(f"File not found: {custom_path}")
                        continue
            
            print("Invalid choice. Please try again.")
            
        except KeyboardInterrupt:
            print("\nOperation cancelled.")
            return None
        except Exception as e:
            print(f"Error: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ê¸°ë³¸ ì„¤ì •
    config = {
        'metadata_path': '../datasets/HSSD/metadata.csv',
        'num_samples': 100,
        'models': [
            'gemma3:1b',
            'qwen3:1.7b', 
            'qwen3:14b'
        ],
        'normalize_output': True,
        'generate_object_names': True
    }
    
    # ì„¤ì • íŒŒì¼ì´ ìˆë‹¤ë©´ ë¡œë“œ
    config_file = 'pipeline_config.json'
    if os.path.exists(config_file):
        try:
            with open(config_file, 'r') as f:
                user_config = json.load(f)
                config.update(user_config)
            print(f"Loaded configuration from {config_file}")
        except Exception as e:
            print(f"Error loading config file: {e}")
    
    # ëª…ë ¹í–‰ ì¸ì ì²˜ë¦¬
    if len(sys.argv) > 1:
        if sys.argv[1] in ['-h', '--help']:
            print("Usage: python run_automated_pipeline.py [metadata_path] [num_samples]")
            print(f"Current config: {json.dumps(config, indent=2)}")
            print(f"\nTo customize, create {config_file} with your settings")
            return
        
        config['metadata_path'] = sys.argv[1]
    else:
        # ë©”íƒ€ë°ì´í„° ê²½ë¡œê°€ ì£¼ì–´ì§€ì§€ ì•Šì•˜ê±°ë‚˜ íŒŒì¼ì´ ì—†ìœ¼ë©´ ì‚¬ìš©ì ì„ íƒ
        if not os.path.exists(config['metadata_path']):
            print(f"Default metadata file not found: {config['metadata_path']}")
            metadata_path = get_metadata_path()
            if not metadata_path:
                print("No metadata file selected. Exiting.")
                return
            config['metadata_path'] = metadata_path
    
    if len(sys.argv) > 2:
        config['num_samples'] = int(sys.argv[2])
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    success = run_pipeline(
        config['metadata_path'],
        config['num_samples'], 
        config['models'],
        config['normalize_output'],
        config['generate_object_names']
    )
    
    if success:
        print("\nğŸ‰ All done! Check the output directory for results.")
    else:
        print("\nâŒ Pipeline failed. Check the error messages above.")
        sys.exit(1)

if __name__ == "__main__":
    main()