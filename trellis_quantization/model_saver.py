"""
TRELLIS ëª¨ë¸ ì €ì¥ ë° ê²°ê³¼ ê´€ë¦¬ í´ë˜ìŠ¤

ê¸°ëŠ¥:
- CSV/JSON ê²°ê³¼ ì €ì¥
- ì–‘ìí™”ëœ ëª¨ë¸ì„ TRELLIS í˜•ì‹ìœ¼ë¡œ ì €ì¥ (config.json + safetensors)
- ì‹œê°í™” ê·¸ë˜í”„ ìƒì„±
"""

import json
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
import pandas as pd
import matplotlib.pyplot as plt
import torch
from safetensors.torch import save_file

# ìƒëŒ€ ì„í¬íŠ¸ ë¬¸ì œ í•´ê²°
try:
    from performance_measurer import PerformanceMeasurer
except ImportError:
    from .performance_measurer import PerformanceMeasurer


class ModelSaver:
    """ëª¨ë¸ ì €ì¥ ë° ê²°ê³¼ ê´€ë¦¬"""
    
    def __init__(self, output_dir: Path):
        self.output_dir = output_dir
        self.measurer = PerformanceMeasurer()
    
    def save_results(self, results: List[Dict[str, Any]], model_name: str):
        """ì‹¤í—˜ ê²°ê³¼ ì €ì¥"""
        try:
            print("ğŸ’¾ ì‹¤í—˜ ê²°ê³¼ ì €ì¥ ì¤‘...")
            
            # CSV ì €ì¥
            df = pd.DataFrame(results)
            csv_path = self.output_dir / f"trellis_{model_name}_results.csv"
            df.to_csv(csv_path, index=False)
            print(f"  âœ… CSV: {csv_path}")
            
            # ì••ì¶• ë©”íŠ¸ë¦­ ê³„ì‚° ë° ì €ì¥
            compression_metrics = self.measurer.calculate_compression_metrics(results)
            if compression_metrics:
                metrics_path = self.output_dir / f"trellis_{model_name}_metrics.json"
                with open(metrics_path, 'w') as f:
                    json.dump(compression_metrics, f, indent=2)
                print(f"  âœ… ë©”íŠ¸ë¦­: {metrics_path}")
                
                # ê²°ê³¼ ì¶œë ¥
                self._print_compression_results(compression_metrics)
            
            # ì‹œê°í™” ìƒì„±
            self._create_visualization(df, model_name)
            
        except Exception as e:
            print(f"âš ï¸ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def save_quantized_model(self, pipeline, model_name: str, original_path: str) -> Optional[str]:
        """ì–‘ìí™”ëœ ëª¨ë¸ì„ TRELLIS í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
        try:
            print("ğŸ’¾ ì–‘ìí™”ëœ ëª¨ë¸ ì €ì¥ ì¤‘...")
            
            # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
            save_dir = self.output_dir / f"trellis_{model_name}_quantized"
            save_dir.mkdir(parents=True, exist_ok=True)
            ckpts_dir = save_dir / "ckpts"
            ckpts_dir.mkdir(parents=True, exist_ok=True)
            
            saved_components = []
            
            # ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ë“¤ì„ config.json + safetensorsë¡œ ì €ì¥
            if hasattr(pipeline, 'models') and pipeline.models:
                for comp_name, model in pipeline.models.items():
                    if model is not None:
                        success = self._save_component_with_config(
                            comp_name, model, ckpts_dir, original_path
                        )
                        if success:
                            safetensors_path = ckpts_dir / f"{comp_name}_quantized_int8.safetensors"
                            if safetensors_path.exists():
                                file_size_mb = safetensors_path.stat().st_size / (1024 * 1024)
                                saved_components.append(f"{comp_name}: {file_size_mb:.1f}MB")
            
            # pipeline.json ìƒì„± (ëª¨ë“  ëª¨ë¸ì„ safetensorsë¡œ í†µì¼)
            self._create_pipeline_config_fixed(save_dir, original_path, saved_components)
            
            # README ìƒì„±
            self._create_readme(save_dir, model_name, original_path, saved_components)
            
            if saved_components:
                print(f"  âœ… {len(saved_components)}ê°œ ì»´í¬ë„ŒíŠ¸ ì €ì¥ ì™„ë£Œ")
                return str(save_dir)
            else:
                print("  âš ï¸ ì €ì¥ëœ ì»´í¬ë„ŒíŠ¸ ì—†ìŒ")
                return None
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None
    
    def _save_component_with_config(self, name: str, model, ckpts_dir: Path, original_path: str) -> bool:
        """ê°œë³„ ì»´í¬ë„ŒíŠ¸ë¥¼ config.json + safetensorsë¡œ ì €ì¥ (ì›ë³¸ í˜¸í™˜ ë°©ì‹)"""
        try:
            print(f"    ğŸ’¾ {name} ì €ì¥ ì¤‘...")
            
            # 1. ì›ë³¸ ëª¨ë¸ì˜ config.json ì°¾ê¸° ë° ë³µì‚¬
            original_config_path = self._find_original_config(name, original_path)
            if original_config_path and original_config_path.exists():
                # config.json ë³µì‚¬
                config_path = ckpts_dir / f"{name}_quantized_int8.json" 
                import shutil
                shutil.copy2(original_config_path, config_path)
                print(f"      âœ… Config: {original_config_path} â†’ {config_path}")
            else:
                # config.jsonì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ê¸°ë³¸ êµ¬ì¡°ë¡œ ìƒì„±
                config_path = ckpts_dir / f"{name}_quantized_int8.json"
                self._create_basic_config(model, config_path)
                print(f"      ğŸ“ ê¸°ë³¸ Config ìƒì„±: {config_path}")
            
            # 2. ëª¨ë¸ì„ ì›ë³¸ í˜•íƒœë¡œ ë³µì› í›„ ì €ì¥
            weights_path = ckpts_dir / f"{name}_quantized_int8.safetensors"
            success = self._save_model_compatible_format(model, weights_path)
            
            if success:
                print(f"      âœ… Weights: {weights_path}")
                return True
            else:
                print(f"      âŒ ì €ì¥ ì‹¤íŒ¨")
                return False
            
        except Exception as e:
            print(f"    âŒ {name} ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def _save_model_compatible_format(self, model, weights_path: Path) -> bool:
        """ëª¨ë¸ì„ ì›ë³¸ í˜¸í™˜ í˜•íƒœë¡œ ì €ì¥"""
        try:
            # CPUë¡œ ì´ë™
            model_cpu = model.cpu()
            
            # ì–‘ìí™” ìƒíƒœ í™•ì¸
            is_quantized = self._is_quantized_model(model_cpu)
            
            if is_quantized:
                # ì–‘ìí™”ëœ ëª¨ë¸: dequantize í›„ ì €ì¥
                print(f"      ğŸ”§ Dequantizing model for compatibility...")
                compatible_state_dict = self._dequantize_model(model_cpu)
            else:
                # ì¼ë°˜ ëª¨ë¸: ê·¸ëŒ€ë¡œ ì €ì¥
                compatible_state_dict = model_cpu.state_dict()
            
            # Non-tensor ê°’ë“¤ ì œê±°
            clean_state_dict = self._clean_quantized_state_dict(compatible_state_dict)
            
            if not clean_state_dict:
                print(f"      âš ï¸ No valid tensors found")
                return False
            
            # safetensorsë¡œ ì €ì¥
            save_file(clean_state_dict, weights_path)
            
            # GPUë¡œ ë³µê·€
            if torch.cuda.is_available():
                model.cuda()
            
            return True
            
        except Exception as e:
            print(f"      âŒ í˜¸í™˜ í˜•íƒœ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def _is_quantized_model(self, model) -> bool:
        """ëª¨ë¸ì´ ì–‘ìí™”ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        try:
            for module in model.modules():
                # _packed_paramsê°€ ìˆìœ¼ë©´ ì–‘ìí™”ëœ ëª¨ë¸
                if hasattr(module, '_packed_params'):
                    return True
                # quantizedê°€ í´ë˜ìŠ¤ëª…ì— í¬í•¨ëœ ê²½ìš°
                if 'quantized' in str(type(module)).lower():
                    return True
            return False
        except:
            return False
    
    def _dequantize_model(self, model) -> dict:
        """ì–‘ìí™”ëœ ëª¨ë¸ì„ ì›ë³¸ í˜•íƒœë¡œ ë³µì›"""
        try:
            import copy
            
            # ìƒˆë¡œìš´ FP32 ëª¨ë¸ ìƒì„±
            dequantized_model = copy.deepcopy(model)
            
            # ì–‘ìí™”ëœ ëª¨ë“ˆë“¤ì„ FP32ë¡œ ë³€í™˜
            self._convert_quantized_modules_to_fp32(dequantized_model)
            
            return dequantized_model.state_dict()
            
        except Exception as e:
            print(f"      âš ï¸ Dequantization ì‹¤íŒ¨, ì–‘ìí™”ëœ state_dict ì‚¬ìš©: {e}")
            return model.state_dict()
    
    def _convert_quantized_modules_to_fp32(self, model):
        """ì–‘ìí™”ëœ ëª¨ë“ˆë“¤ì„ FP32ë¡œ ë³€í™˜"""
        try:
            for name, module in model.named_modules():
                if hasattr(module, '_packed_params'):
                    # Linear ë ˆì´ì–´ ë³€í™˜
                    if hasattr(module, 'in_features') and hasattr(module, 'out_features'):
                        # ì–‘ìí™”ëœ ê°€ì¤‘ì¹˜ ì¶”ì¶œ
                        weight, bias = module._weight_bias()
                        
                        # ìƒˆë¡œìš´ FP32 Linear ë ˆì´ì–´ ìƒì„±
                        new_linear = torch.nn.Linear(
                            module.in_features, 
                            module.out_features,
                            bias=bias is not None
                        )
                        
                        # ê°€ì¤‘ì¹˜ ë³µì‚¬
                        new_linear.weight.data = weight.dequantize()
                        if bias is not None:
                            new_linear.bias.data = bias
                        
                        # ëª¨ë“ˆ êµì²´
                        parent_name = '.'.join(name.split('.')[:-1])
                        child_name = name.split('.')[-1]
                        
                        if parent_name:
                            parent = model.get_submodule(parent_name)
                            setattr(parent, child_name, new_linear)
                        else:
                            setattr(model, child_name, new_linear)
                            
        except Exception as e:
            print(f"      âš ï¸ FP32 ë³€í™˜ ì¤‘ ì¼ë¶€ ì‹¤íŒ¨: {e}")
            # ê³„ì† ì§„í–‰
    
    def _find_original_config(self, comp_name: str, original_path: str) -> Optional[Path]:
        """ì›ë³¸ ëª¨ë¸ì˜ config.json íŒŒì¼ ì°¾ê¸°"""
        original_path = Path(original_path)
        
        # pipeline.jsonì—ì„œ ì›ë³¸ ê²½ë¡œ ë§¤í•‘ ì°¾ê¸°
        pipeline_json = original_path / "pipeline.json"
        if pipeline_json.exists():
            try:
                with open(pipeline_json, 'r') as f:
                    config = json.load(f)
                
                if 'args' in config and 'models' in config['args']:
                    original_model_path = config['args']['models'].get(comp_name)
                    if original_model_path:
                        # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                        if original_model_path.startswith('../'):
                            # ../TRELLIS-image-large/ckpts/... í˜•íƒœ
                            abs_path = original_path.parent / original_model_path[3:]
                        else:
                            # ckpts/... í˜•íƒœ
                            abs_path = original_path / original_model_path
                        
                        config_path = abs_path.with_suffix('.json')
                        if config_path.exists():
                            return config_path
                        
                        # ì§ì ‘ ê²½ë¡œë„ ì‹œë„
                        direct_config = Path(f"{abs_path}.json")
                        if direct_config.exists():
                            return direct_config
                            
            except Exception as e:
                print(f"      âš ï¸ pipeline.json íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        return None
    
    def _create_basic_config(self, model, config_path: Path):
        """ê¸°ë³¸ config.json ìƒì„± (ì›ë³¸ì„ ì°¾ì„ ìˆ˜ ì—†ì„ ë•Œ)"""
        try:
            # ëª¨ë¸ í´ë˜ìŠ¤ëª… ì¶”ì¶œ
            model_class_name = model.__class__.__name__
            
            # ê¸°ë³¸ ì„¤ì • ìƒì„±
            basic_config = {
                "name": model_class_name,
                "args": {},
                "quantization_info": {
                    "method": "dynamic_int8",
                    "note": "Basic config generated automatically"
                }
            }
            
            with open(config_path, 'w') as f:
                json.dump(basic_config, f, indent=2)
                
        except Exception as e:
            print(f"      âš ï¸ ê¸°ë³¸ config ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _clean_quantized_state_dict(self, state_dict: dict) -> dict:
        """ì–‘ìí™”ëœ ëª¨ë¸ì˜ state_dictì—ì„œ non-tensor ê°’ë“¤ ì œê±°"""
        if state_dict is None:
            return {}
            
        clean_dict = {}
        skipped_keys = []
        
        for key, value in state_dict.items():
            if isinstance(value, torch.Tensor):
                clean_dict[key] = value
            else:
                skipped_keys.append(f"{key} ({type(value).__name__})")
        
        if skipped_keys:
            print(f"      âš ï¸ Non-tensor keys skipped: {len(skipped_keys)}")
            for key in skipped_keys[:3]:  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
                print(f"        - {key}")
            if len(skipped_keys) > 3:
                print(f"        ... and {len(skipped_keys)-3} more")
        
        return clean_dict
    
    def _create_pipeline_config_fixed(self, save_dir: Path, original_path: str, saved_components: List[str]):
        """pipeline.json ì„¤ì • íŒŒì¼ ìƒì„± (ëª¨ë“  ëª¨ë¸ì„ safetensorsë¡œ í†µì¼)"""
        try:
            # ì›ë³¸ ì„¤ì • ì½ê¸°
            original_config_path = Path(original_path) / "pipeline.json"
            if original_config_path.exists():
                with open(original_config_path, 'r') as f:
                    config = json.load(f)
                
                # ëª¨ë¸ ê²½ë¡œë¥¼ ì–‘ìí™” ë²„ì „ìœ¼ë¡œ ìˆ˜ì • (ëª¨ë‘ safetensors)
                if 'args' in config and 'models' in config['args']:
                    for model_name in config['args']['models']:
                        config['args']['models'][model_name] = f"ckpts/{model_name}_quantized_int8"
                
                # ì–‘ìí™” ì •ë³´ ì¶”ê°€
                config['quantization_info'] = {
                    'method': 'dynamic_int8',
                    'original_model': original_path,
                    'quantized_date': time.strftime('%Y-%m-%d %H:%M:%S'),
                    'saved_components': [comp.split(':')[0] for comp in saved_components],
                    'note': 'All models saved as safetensors with quantization metadata cleaned'
                }
                
                # ì €ì¥
                config_path = save_dir / "pipeline.json"
                with open(config_path, 'w') as f:
                    json.dump(config, f, indent=2)
                
                print(f"    âœ… pipeline.json ìƒì„±")
                
        except Exception as e:
            print(f"    âš ï¸ pipeline.json ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _create_readme(self, save_dir: Path, model_name: str, original_path: str, saved_components: List[str]):
        """README.md ìƒì„±"""
        readme_path = save_dir / "README.md"
        with open(readme_path, 'w') as f:
            f.write(f"""# TRELLIS {model_name.upper()} Quantized Model (INT8)

## ğŸ“‹ ëª¨ë¸ ì •ë³´
- **ì›ë³¸ ëª¨ë¸**: {original_path}
- **ì–‘ìí™” ë°©ë²•**: Dynamic INT8 Quantization
- **ì–‘ìí™” ì¼ì‹œ**: {time.strftime('%Y-%m-%d %H:%M:%S')}
- **ì €ì¥ëœ ì»´í¬ë„ŒíŠ¸**: {len(saved_components)}ê°œ

## ğŸš€ ì‚¬ìš© ë°©ë²•

```python
from trellis.pipelines import TrellisTextTo3DPipeline

# ì–‘ìí™”ëœ ëª¨ë¸ ë¡œë“œ
pipeline = TrellisTextTo3DPipeline.from_pretrained("{save_dir}")
pipeline.cuda()

# 3D ìƒì„±
outputs = pipeline.run("a red sports car", seed=42)

# ê²°ê³¼ ì €ì¥
from trellis.utils import postprocessing_utils
glb = postprocessing_utils.to_glb(outputs['gaussian'][0], outputs['mesh'][0])
glb.export("output.glb")
```

## ğŸ“Š ì €ì¥ëœ ì»´í¬ë„ŒíŠ¸
""")
            for component in saved_components:
                f.write(f"- {component}\n")
            
            f.write(f"""
## âš ï¸ ì£¼ì˜ì‚¬í•­
- INT8 ì–‘ìí™”ë¡œ ì¸í•´ ì›ë³¸ ëŒ€ë¹„ ì•½ê°„ì˜ í’ˆì§ˆ ì €í•˜ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
- GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ì¶”ë¡  ì†ë„ëŠ” ê°œì„ ë©ë‹ˆë‹¤

## ğŸ”§ íŒŒì¼ êµ¬ì¡°
- `pipeline.json`: íŒŒì´í”„ë¼ì¸ ì„¤ì •
- `ckpts/*.json`: ê° ì»´í¬ë„ŒíŠ¸ì˜ ëª¨ë¸ ì„¤ì •
- `ckpts/*.safetensors`: ì–‘ìí™”ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜
- `README.md`: ì‚¬ìš© ê°€ì´ë“œ
""")
    
    def _create_visualization(self, df: pd.DataFrame, model_name: str):
        """ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”"""
        try:
            if len(df) < 2:
                return
            
            # ì—ëŸ¬ê°€ ìˆëŠ” í–‰ ì œì™¸
            df_clean = df[~df.get('error', pd.Series(False, index=df.index)).notna()]
            if df_clean.empty:
                return
            
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))
            
            # 1. íŒŒë¼ë¯¸í„° ìˆ˜
            ax1.bar(df_clean['model_name'], df_clean['total_params_M'])
            ax1.set_title('Model Parameters (M)')
            ax1.set_ylabel('Parameters (Millions)')
            
            # 2. ëª¨ë¸ í¬ê¸°
            ax2.bar(df_clean['model_name'], df_clean['model_size_MB'])
            ax2.set_title('Model Size (MB)')
            ax2.set_ylabel('Size (MB)')
            
            # 3. GPU ë©”ëª¨ë¦¬
            ax3.bar(df_clean['model_name'], df_clean['gpu_memory_MB'])
            ax3.set_title('GPU Memory Usage (MB)')
            ax3.set_ylabel('Memory (MB)')
            
            # 4. ì¶”ë¡  ì‹œê°„
            ax4.bar(df_clean['model_name'], df_clean['inference_time_ms'])
            ax4.set_title('Inference Time (ms)')
            ax4.set_ylabel('Time (ms)')
            
            plt.tight_layout()
            
            # ì €ì¥
            plot_path = self.output_dir / f"trellis_{model_name}_comparison.png"
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"  âœ… ì‹œê°í™”: {plot_path}")
            
        except Exception as e:
            print(f"  âš ï¸ ì‹œê°í™” ì‹¤íŒ¨: {e}")
    
    def _print_compression_results(self, metrics: Dict[str, float]):
        """ì••ì¶• ê²°ê³¼ ì¶œë ¥"""
        print(f"\nğŸ¯ ì••ì¶• íš¨ê³¼:")
        print(f"  â€¢ ì••ì¶•ë¥ : {metrics['compression_ratio']:.1f}x")
        print(f"  â€¢ í¬ê¸° ê°ì†Œ: {metrics['size_reduction_percent']:.1f}%")
        print(f"  â€¢ ë©”ëª¨ë¦¬ ì ˆì•½: {metrics['memory_reduction_percent']:.1f}%")
        print(f"  â€¢ ì†ë„ ë³€í™”: {metrics['speed_change_percent']:+.1f}%")
        print(f"  â€¢ í’ˆì§ˆ ì†ì‹¤: {metrics['quality_loss_percent']:.1f}%")
        print(f"  â€¢ íš¨ìœ¨ì„± ì ìˆ˜: {metrics['efficiency_score']:.3f}")